{"cells":[{"cell_type":"markdown","source":["Randorm Forest Classifier class definition `RFCModel`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7a3b0725-f38d-43f7-9fc6-ac3cd22d4e45"}}},{"cell_type":"code","source":["import mlflow.sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score\n\nclass RFCModel():\n\n    def __init__(self, params={}):\n        \"\"\"\n        Constructor for RandamForestClassifier\n        :param params: parameters for the constructor such as no of estimators, depth of the tree, random_state etc\n        \"\"\"\n        self._rf = RandomForestClassifier(**params)\n        self._params = params\n\n    @classmethod\n    def new_instance(cls, params={}):\n        return cls(params)\n\n    @property\n    def model(self):\n        \"\"\"\n        Getter for the property the model\n        :return: return the model\n        \"\"\"\n        \n        return self._rf\n  \n    @property \n    def params(self):\n      \"\"\"\n      Getter for the property the model\n        :return: return the model params\n      \"\"\"\n      return self._params\n    \n    def mlflow_run(self, df, r_name=\"Lab-2:RF Bank Note Classification Experiment\"):\n        \"\"\"\n        This method trains, computes metrics, and logs all metrics, parameters,\n        and artifacts for the current run\n        :param df: pandas dataFrame\n        :param r_name: Name of the experiment as logged by MLflow\n        :return: MLflow Tuple (ExperimentID, runID)\n        \"\"\"\n\n        with mlflow.start_run(run_name=r_name) as run:\n          \n            # get current run and experiment id\n            runID = run.info.run_uuid\n            experimentID = run.info.experiment_id\n            \n            # get all rows and columns but the last column, which is our class\n            X = df.iloc[:, 0:4].values\n            # get all observed values in the last columns, which is what we want to predict\n            y = df.iloc[:, 4].values\n\n            # create train and test data\n            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\n            # Feature Scaling\n            sc = StandardScaler()\n            X_train = sc.fit_transform(X_train)\n            X_test = sc.transform(X_test)\n\n            # train and predict\n            self._rf.fit(X_train, y_train)\n            y_pred = self._rf.predict(X_test)\n\n            # Log model and params using the MLflow sklearn APIs\n            mlflow.sklearn.log_model(self.model, \"random-forest-class-model\")\n            mlflow.log_params(self.params)\n\n            # compute evaluation metrics\n            acc = accuracy_score(y_test, y_pred)\n            precision = precision_score(y_test, y_pred)\n            conf_matrix = confusion_matrix(y_test,y_pred)\n            \n            # ROC = summary of all confusion matrices that each\n            # threshold produces\n            roc = metrics.roc_auc_score(y_test, y_pred)\n\n            # get confusion matrix values\n            true_positive = conf_matrix[0][0]\n            true_negative = conf_matrix[1][1]\n            false_positive = conf_matrix[0][1]\n            false_negative = conf_matrix[1][0]\n\n            # get classification matrics as a dictionary\n            class_report = classification_report(y_test,y_pred, output_dict=True)\n            recall_0 = class_report['0']['recall']\n            f1_score_0 = class_report['0']['f1-score']\n            recall_1 = class_report['1']['recall']\n            f1_score_1 = class_report['1']['f1-score']\n\n            # log metrics\n            mlflow.log_metric(\"accuracy_score\", acc)\n            mlflow.log_metric(\"precision\", precision)\n            mlflow.log_metric(\"true_positive\", true_positive)\n            mlflow.log_metric(\"true_negative\", true_negative)\n            mlflow.log_metric(\"false_positive\", false_positive)\n            mlflow.log_metric(\"false_negative\", false_negative)\n            mlflow.log_metric(\"recall_0\", recall_0)\n            mlflow.log_metric(\"f1_score_0\", f1_score_0)\n            mlflow.log_metric(\"recall_1\", recall_1)\n            mlflow.log_metric(\"f1_score_1\", f1_score_1)\n            mlflow.log_metric(\"roc\", roc)\n\n            # create confusion matrix images\n            (plt, fig, ax) = Utils.plot_confusion_matrix(y_test, y_pred, y, title=\"Bank Note Classification Confusion Matrix\")\n\n            # create temporary artifact file name and log artifact\n            temp_file_name = Utils.get_temporary_directory_path(\"confusion_matrix-\", \".png\")\n            temp_name = temp_file_name.name\n            try:\n                fig.savefig(temp_name)\n                mlflow.log_artifact(temp_name, \"confusion_matrix_plots\")\n            finally:\n                temp_file_name.close()  # Delete the temp file\n\n            # print some data\n            print(\"-\" * 100)\n            print(\"Inside MLflow Run with run_id {} and experiment_id {}\".format(runID, experimentID))\n            print(\"Estimators trees:\", self.params[\"n_estimators\"])\n            print(conf_matrix)\n            print(classification_report(y_test,y_pred))\n            print(\"Accuracy Score:\", acc)\n            print(\"Precision     :\", precision)\n            print(\"ROC           :\", roc)\n\n            return (experimentID, runID)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"40c17b9a-005a-430e-b976-be03d9653b9e"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["displayHTML(\"\"\"\n<div>Declared RandomForestClassifierModel Class with methods:</div>\n<li>Declared <b style=\"color:green\">model()</b> returns existing instance of Random Forest Model</li>\n<li>Declared <b style=\"color:green\">params()</b> returns existing Random Forest Model's init parameters.</li>\n<li>Declared <b style=\"color:green\">new_instance(params={...})</b> returns a new instance of RandomForestClassifierModel</li> \n<li>Declared <b style=\"color:green\"> mlflow_run(DataFrame, run_name=\"name\")</b> returns experiment_ID, run_ID</li>\n\n<br/>\n\"\"\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"080158d8-916e-4ab2-bc1b-cd0b7fc5bf1d"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"rfc_classification_cls","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2387317862617845}},"nbformat":4,"nbformat_minor":0}
